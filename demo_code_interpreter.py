import os

from dotenv import load_dotenv
load_dotenv(".env", override=True)

from python_code_interpreter_tool import PythonExecTool
from openai import OpenAI
import requests
import json

openai_api_key = os.getenv("OPENAI_API_KEY")

def get_completion(messages, model="gpt-4.1-mini", temperature=0, tools=None, tool_choice=None, parallel_tool_calls=True):
  payload = { "model": model, "store": True, "temperature": temperature, "messages": messages, "store": True }
  if tools:
    payload["tools"] = tools
    payload["parallel_tool_calls"] = parallel_tool_calls

    if tool_choice:
      payload["tool_choice"] = tool_choice

  headers = { "Authorization": f'Bearer {openai_api_key}', "Content-Type": "application/json" }
  response = requests.post('https://api.openai.com/v1/chat/completions', headers = headers, data = json.dumps(payload) )
  obj = json.loads(response.text)

  if response.status_code == 200 :
    return obj["choices"][0]["message"] # æ”¹æˆå›å‚³ä¸Šä¸€å±¤ message ç‰©ä»¶
  else :
    return obj["error"]
  
def execute_python_code(python_code: str) -> str:
    """
    Execute the provided Python code and return the output.
    """
    tool = PythonExecTool()
    try:
        # å°‡å­—ä¸²åŒ…è£æˆå­—å…¸æ ¼å¼
        result = tool.run({"python_code": python_code})
        return str(result)
    except Exception as e:
        import traceback
        return f"åŸ·è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\n{traceback.format_exc()}"

available_tools = {
  "execute_python_code": execute_python_code,
}

def run_full_turn(messages, model="gpt-4.1", temperature=0, tools=None, tool_choice=None, parallel_tool_calls=True):
  # print(f"ğŸ’¬ å‘¼å« API: {messages}")
  response = get_completion(messages, model=model, temperature=temperature, tools=tools,tool_choice=tool_choice,parallel_tool_calls=parallel_tool_calls)

  if response.get("tool_calls"): # æˆ–ç”¨ response è£¡é¢çš„ finish_reason åˆ¤æ–·ä¹Ÿè¡Œ
    messages.append(response)

    # ------ å‘¼å«å‡½æ•¸ï¼Œé€™è£¡æ”¹æˆåŸ·è¡Œå¤š tool_calls (å¯ä»¥æ”¹æˆå¹³è¡Œè™•ç†ï¼Œç›®å‰ç”¨ç°¡å–®çš„è¿´åœˆ)
    for tool_call in response["tool_calls"]:
      function_name = tool_call["function"]["name"]
      function_args = json.loads(tool_call["function"]["arguments"])
      function_to_call = available_tools[function_name]

      print(f"   âš™ï¸ å‘¼å«å‡½å¼ {function_name} åƒæ•¸ {function_args}")
      function_response = function_to_call(**function_args)
      messages.append(
          {
              "tool_call_id": tool_call["id"], # å¤šäº† toll_call_id
              "role": "tool",
              "name": function_name,
              "content": str(function_response), # ä¸€å®šè¦æ˜¯å­—ä¸²
          }
      )

    # é€²è¡Œéè¿´å‘¼å«
    return run_full_turn(messages, model=model, temperature=temperature, tools=tools,tool_choice=tool_choice,parallel_tool_calls=parallel_tool_calls)

  else:
    return response["content"] 


system_prompt = """You are a helpful data science assistant. Your role is to analyze data and generate Python code to answer user queries effectively.

## Core Responsibilities

1. Process data as specified by the user
2. Generate Python code for data analysis
3. Execute the code using the `execute_python_code` tool
4. Explain the findings to the user

## Technical Capabilities

You can utilize the following Python libraries:
- pandas
- numpy
- matplotlib and seaborn
- scikit-learn

## Workflow

1. Understand the user's question and data
2. Write efficient Python code
3. Run the code using the tool
4. Interpret the results and provide insights

## Output Requirements

Always provide your explanations and insights in Traditional Chinese (Taiwan). The code will be in Python (English), but all your analysis, interpretations, and communications must be in Chinese.
"""

messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": """æˆ‘æƒ³äº†è§£Pythonæ•¸æ“šåˆ†æçš„åŸºæœ¬æµç¨‹ã€‚è«‹ç¤ºç¯„å¦‚ä½•ï¼š

1. ç”Ÿæˆä¸€å€‹æ¨¡æ“¬çš„éŠ·å”®æ•¸æ“šé›†ï¼ŒåŒ…å«æ—¥æœŸã€ç”¢å“é¡åˆ¥ã€éŠ·å”®é¡å’Œå®¢æˆ¶å¹´é½¡
2. è¨ˆç®—ä¸¦é¡¯ç¤ºå„ç”¢å“é¡åˆ¥çš„éŠ·å”®ç¸½é¡å’Œå¹³å‡å€¼
3. è¨ˆç®—éŠ·å”®é¡èˆ‡å®¢æˆ¶å¹´é½¡çš„ç›¸é—œä¿‚æ•¸
4. ä½¿ç”¨ç°¡å–®çš„æ©Ÿå™¨å­¸ç¿’æ¨¡å‹é æ¸¬éŠ·å”®é¡ï¼Œä¸¦é¡¯ç¤ºé æ¸¬æº–ç¢ºåº¦
5. è¼¸å‡ºé—œéµçµ±è¨ˆæŒ‡æ¨™ï¼ˆå¦‚æœ€é«˜/æœ€ä½éŠ·å”®é¡ã€æ¨™æº–å·®ç­‰ï¼‰

ä¸éœ€è¦ä½¿ç”¨ä»»ä½•å¤–éƒ¨æ–‡ä»¶ï¼Œè«‹ç›´æ¥åœ¨ä»£ç¢¼ä¸­ç”Ÿæˆæ¨¡æ“¬æ•¸æ“šï¼Œä¸¦åªä½¿ç”¨ print è¼¸å‡ºè¨ˆç®—çµæœï¼Œä¸éœ€è¦è¦–è¦ºåŒ–åœ–è¡¨ã€‚"""}]
tools = [PythonExecTool().get_definition()]

response = run_full_turn(messages, tools=tools)
print("------")
print(response)
